双大模型逻辑分歧自动检测与结构化解耦系统：架构与开发技术路线
1. 系统总体架构说明

本系统旨在在本地服务器上运行一个 Python 程序，自动调用多个大型语言模型（例如 OpenAI 的 GPT 系列和 Anthropic 的 Claude），对比它们对同一输入问题的回答，检测其中的逻辑分歧，并通过结构化方式解耦冲突信息，最后融合生成统一的输出答案。整个系统采用模块化的架构设计，各模块依次流水线式工作，并由主控流程串联。主要模块包括：模型调用模块、分歧检测模块、结构化解耦模块、融合生成模块以及数据库管理模块。各模块之间通过清晰的接口传递数据，所有交互过程中的中间结果（模型回答、分歧分析、解耦结构、融合结果等）都将存储在本地数据库中用于缓存和追踪。数据库的引入保证了对话和分析过程具有可追溯性，同时避免重复调用模型以节省成本。

模块之间的依赖关系和系统流程如下图所示：模型调用模块并行或顺序地调用GPT和Claude模型获取结果，经由分歧检测模块对比两者输出，结构化解耦模块将分歧点重组为结构化数据，融合生成模块据此产出最终答案；整个过程中数据库模块贯穿始终，用于缓存和记录各阶段数据，供后续模块查询利用。

flowchart LR
    subgraph 系统架构
    direction LR
    user(用户请求)
    MI[模型调用模块] -->|调用| GPT_API[OpenAI GPT API]
    MI -->|调用| Claude_API[Anthropic Claude API]
    GPT_API -->|回答| MI
    Claude_API -->|回答| MI
    MI -->|存储回答| DB[(本地数据库)]
    MI --> DD[分歧检测模块]
    DD -->|存储分歧| DB
    DD --> SD[结构化解耦模块]
    SD -->|存储结构| DB
    SD --> FG[融合生成模块]
    FG -->|存储答案| DB
    FG --> output(融合答案输出)
    end
    user --> MI
    output --> user

图：系统模块与依赖关系示意图。用户提出问题，经模型调用器请求两个大模型获取回答，再依次经过分歧检测、结构化解耦和融合生成处理，最终输出答案。所有中间结果均存储进数据库作为缓存。
2. 技术选型与依赖说明

本节说明系统实现所采用的编程语言、模型接口方案、数据库类型以及相关依赖库等技术选型。

    编程语言与运行环境：采用 Python 语言开发（建议Python 3.9或以上版本，以兼容Anthropic官方SDK）。Python拥有丰富的机器学习和数据库库，并且易于脚本化自动运行，非常适合此项目。本地运行可使用虚拟环境来隔离依赖，方便管理。

    大型模型 API 接口：系统通过官方提供的 SDK/HTTP API 与大模型交互：

        OpenAI GPT 接口：使用 OpenAI 提供的 Python SDK（openai库）调用 GPT-4/GPT-3.5 等模型。程序将通过读取环境变量中的 OPENAI_API_KEY 来加载API密钥进行认证。OpenAI官方库支持自动从系统环境获取 API Key。开发时可借助 python-dotenv 从.env文件加载该密钥，避免将敏感信息硬编码在源代码中。

        Anthropic Claude 接口：使用 Anthropic 官方的 Python SDK（anthropic库）对接 Claude 模型。类似地，配置环境变量 ANTHROPIC_API_KEY 用于认证，并可通过.env文件管理该密钥。Anthropic SDK 接口设计与 OpenAI 相仿，支持同步或异步调用，为Claude模型的对话生成提供便捷封装。

        两大模型接口均采用标准的RESTful调用方式，支持将用户输入作为prompt或messages发送，返回模型生成的文本结果。通过SDK可以指定模型名称、最大返回长度、温度等参数。由于本系统需要并行调用多个模型，可选择使用Python的并发库（如asyncio或多线程）以减少总等待时间；同时需注重调用频率和配额限制（可通过缓存降低API调用次数）。

    数据库方案：采用 SQLite 作为默认数据库后端。SQLite是Python内置支持的轻量级嵌入式关系型数据库，无需单独安装服务器进程，使用一个本地文件即可完成读写。这一特性非常适合在用户本地服务器上自动部署和维护数据库。系统首次运行时将自动创建所需的表结构（如无该数据库文件则自动生成），无需用户干预。SQLite能可靠地存储文本数据（如模型回答、分析结果），并支持基本的SQL查询用于按问题ID检索相关记录。对于并发访问，单用户本地应用SQLite完全足够。如未来需要扩展到多用户或大规模数据，也可以切换到更强大的数据库（如PostgreSQL、MySQL或文档数据库MongoDB等），但在当前场景下SQLite实现零配置即可满足需求。

    必要的第三方库：除上述模型SDK和SQLite外，还将用到一些Python库：

        差异比较：使用标准库的 difflib 或 re 来进行文本对比，标识模型回答之间的差异片段（例如生成diff字符串或找到不同句子）。

        自然语言处理（可选）：为实现更高级的分歧分析和结构化表示，可选用 NLTK、spaCy 等库进行文本分句、词性标注、命名实体识别等预处理，或使用 transformers 提供的预训练模型做文本相似度计算或矛盾检测。这些依赖在基础阶段不是必须的，但在高级阶段（例如引入知识图谱）可能有帮助。

        HTTP 请求：如果在证据检索阶段需要访问外部知识源，可使用 requests 库调用搜索引擎API或查询维基百科API等。也可使用专门的wikipedia库来直接获取维基内容。需注意加入这些调用时的网络安全和延迟。

        数据处理和图结构：在知识图谱阶段，可能使用如 networkx 来构建和操作知识图谱结构，方便对比节点关系；或使用 pandas 辅助数据整理。基础阶段暂时不需要这些库。

        环境配置：使用 python-dotenv 库读取 .env 文件，方便管理API密钥等配置。此外，为提高代码质量，可使用 pytest 编写单元测试，使用 logging 记录运行日志。

    上述依赖可通过 pip 安装，系统将提供 requirements.txt 列出所需的库版本。

3. 模块功能说明

系统各功能模块划分如下，每个模块负责完成特定的任务，模块之间通过函数调用或数据接口衔接。下面对各模块的职责和内部逻辑进行说明：

    模型调用模块（Model Invoker）：负责与外部大模型API接口通信。它接收用户提出的问题（或任务描述），根据预定的提示模板封装成API请求，向多个大型语言模型发送请求并获取它们的回答。该模块支持调用不同模型，可以针对OpenAI GPT和Anthropic Claude分别配置调用逻辑（如模型名称、API端点等）。为提高效率，模型调用器可以并行地向两个API发送请求（例如使用异步IO）。它在拿到模型返回结果后，会将原始回答文本以及相关元数据（模型名称、调用时间、token用量等）存入数据库缓存，以便后续模块使用和避免重复调用。缓存机制：在调用API之前，模块调用器应查询数据库看是否已有相同问题和模型的回答缓存；如果有则可直接读取缓存而跳过API请求，以节约调用次数和加快响应。如果没有缓存则正常调用API并写入缓存。该模块需处理可能出现的异常情况，如API超时、网络错误或配额超限，出现错误时可以重试或记录错误状态到数据库。

    分歧检测模块（Divergence Detector）：负责比较两个模型给出的回答，找出其中内容上的差异和冲突之处。它从数据库或模型调用模块直接获取两份回答文本，运用文本比较算法和NLP技术识别出两者在事实陈述、结论推理等方面的不一致点。分歧检测可以分层进行：

        首先进行文本差异比对：利用 difflib 的序列匹配算法对两段文本做逐行或逐句比较，找到明显不同的句子或片段，并标记哪些内容只出现在一个回答中。

        然后进行语义分歧分析：针对初步发现的差异，进一步判断其性质。例如，是措辞表述不同但含义相同，还是在事实/逻辑上直接冲突。对于逻辑/事实冲突点，可标记为“关键分歧”。必要时，可以调用某种**自然语言推理（NLI）**模型或启用另一大型模型来判断一句话是否与另一句矛盾或蕴涵。

        最终输出分歧报告：模块将生成一个结构化的结果，描述发现的所有差异点。可以采用列表或字典结构列出每个分歧：包括分歧内容简述、在哪个模型回答中出现以及分歧类型（例如“模型A独有信息”、“模型B独有信息”、“矛盾冲突”等）。这一结果会存储在数据库中用于后续处理，同时也便于日志记录。【注】如果两个模型回答在内容上完全一致，分歧检测模块应返回一个表示“无显著分歧”的结果，主流程据此可以直接跳过融合步骤或简单返回答案。

    结构化解耦模块（Structured Decoupler）：负责将两个模型回答中混杂在一起的不同观点、逻辑链条进行重组，以明确区分各自的逻辑成分。简单来说，就是把两份答案的内容按照主题或论点进行拆解重排，形成一个对照或融合的结构，使差异点和共同点都更清晰地呈现。其具体功能包括：

        要点提取与对齐：分析两份回答的内容结构，抽取其中的关键要点或段落（例如按问题的各个方面、技术方案的各个要素等拆分）。然后将两份回答的要点进行对齐：找出对应的主题部分，以及哪些要点是一方有而另一方没有提及。

        逻辑解耦：对于存在逻辑分歧的部分，将冲突的陈述分开表述。例如，如果模型A认为原因是X，模型B认为原因是Y，解耦模块会将“原因”这个逻辑点单独拿出，并分别记录X和Y两个不同的说法，而不掺杂在各自原答案长段落中。这样相当于建立一个“结构化对照表”，每个结构单元对应一个逻辑点，下挂两个模型不同的观点。

        结构化表示：将上述解耦后的内容组织成统一的结构，可以是树状的大纲、表格形式或者JSON文档。例如可以输出一个JSON，其中顶层是各个主题/要点，每个要点下包含model_A_contribution和model_B_contribution字段对应两模型对此要点的表述。如果两者一致则可以合并表述。也可以采用Markdown列表或表格形式呈现，方便后续融合参考。

        结构化解耦的结果会保存至数据库，供融合模块使用。这个模块的作用是为融合创造基础：经过结构化处理后，系统将更容易逐点比较并综合信息，而不是直接处理两大段未经整理的文本。

    融合生成模块（Fusion Generator）：负责基于前一模块产生的结构化差异数据，生成最终面向用户的答案输出。融合模块相当于一名“撰稿人”，它会综合两个模型的回答优点，解决它们之间的冲突，产出一个质量更高、信息更全面一致的答案。其主要功能包括：

        冲突消解：对于分歧检测标记出的矛盾之处，融合模块需要决定如何处理。可能的策略包括：引用证据来判定真伪（在阶段2中实现）、或者在答案中同时陈述两种观点并加以对比说明。如果有明确正确/权威的信息，融合模块应当选取正确的部分。对于暂无法确定真假的，可在答案中保留两种可能性说明，或根据上下文倾向其中一个并给出理由。

        内容合并补全：将两个模型回答中互补的信息合并。在结构化解耦结果中，每个要点下可能有两边各自的表述，融合时应尽量将两者糅合成一段连贯的表述，吸收双方的有用内容，避免重复。比如模型A提到了某技术的三个优点，模型B补充了另外两个，融合后答案应包含五个优点，全方面覆盖。

        语言风格统一：两个模型的写作风格可能不同（用词、语气等），融合模块生成输出时应调整措辞，使得最终答案风格一致、流畅可读，而不是简单拼接。同时保持专业和准确的语气，满足专利撰写等应用场景对严谨性的要求。

        结构组织：根据解耦的逻辑结构，安排最终答案的段落顺序。必要时可以引入段落标题、小结等增强可读性。例如，如果问题本身包含多个子问题，可按子问题分别融合回答，再整合。

        模型答案溯源（可选）：融合输出中可以隐含或显式地反映每部分信息的来源，以确保透明度。例如在开发和测试阶段，可以在合成答案的注释或log中注明“(本段结合了GPT的观点X和Claude的观点Y)”以便调试。但对最终用户输出则通常不显式标注来源，以提供单一一致的答案。

        输出生成：融合模块实现可以采取两种途径：其一，基于程序逻辑拼接和模板生成；其二，借助大型语言模型本身来进行自然语言生成（即提示词融合法，将结构化内容作为Prompt的一部分，令GPT或Claude撰写最终答案）。在自动化系统中，可以使用GPT-4等模型作为“稿件合成AI”，输入如“请根据以下要点，用一致的风格撰写一段答案...”的提示，让其编写融合后的答案文本。这种方式往往能得到更流畅的表述，但需要注意控制不引入新错误。无论采取何种方式，最终生成的答案文本都会存储到数据库，并返回给用户。

    数据库管理模块（Database Manager）：这是系统的辅助模块，负责数据库的初始化和读写封装。由于系统需要频繁读写缓存数据，数据库管理模块将提供统一的接口函数，例如：init_db() 创建所需的表结构；save_response(question_id, model_name, content) 保存模型回答；get_cached_response(question_text, model_name) 根据问题内容和模型名称查询缓存；save_diff(question_id, diff_data) 保存分歧分析结果；save_fusion(question_id, fused_answer) 保存融合后的最终答案等等。这样可以在主流程和各功能模块中调用这些接口，而由数据库管理模块负责执行具体的SQL操作。数据库管理模块在初始化时会检测当前是否已有配置（例如选择SQLite还是其他数据库），如果没有则默认使用SQLite并在工作目录下创建文件。它还可以包含简单的维护策略，比如定期清理过旧的缓存记录，以节省空间。鉴于SQLite的易用性，大多数数据库操作可以用标准库sqlite3直接执行，但如果逻辑复杂，也可以考虑使用轻量ORM简化开发。总之，该模块确保数据库操作对其余系统是透明的，用户无需关心数据库细节。

上述各模块分工明确，各司其职。主控流程（位于 main 脚本中）会按照顺序协调调用：接受用户输入，调用模型获取答案，调用分歧检测分析差异，调用解耦模块生成结构化数据，最后调用融合模块得到输出，并将结果提供给用户。模块化设计使得每个组件都可以独立测试和改进，并且在后续阶段可以替换或增强某些模块（例如插入证据检索模块、知识图谱模块）而不会影响整个系统框架的稳定性。
4. 数据库结构设计

根据系统需求，数据库需要存储的问题、模型回答、中间分析结果以及最终融合答案等数据。鉴于数据类型较为多样（文本、结构化内容等），可采用关系型数据库的多张表来分别存储，并通过外键关联。同样也可以使用文档型数据库将相关内容嵌入存储。但这里以关系数据库设计为例，提供清晰的表结构。

采用SQLite关系数据库设计以下基本表：

    Table: queries（用户查询表） – 存储用户提出的问题或任务。

        id (INTEGER, PK): 查询ID，自增主键。

        question_text (TEXT): 用户的查询内容（问题文本）。

        created_at (TIMESTAMP): 提出时间戳（系统自动记录）。

    Table: model_responses（模型回答表） – 存储各大模型对某一查询的回答内容。

        id (INTEGER, PK): 回答记录ID，自增主键。

        query_id (INTEGER): 外键关联到 queries.id，标识属于哪个用户查询。

        model_name (TEXT): 模型名称（例如 "GPT-4"、"Claude-2" 等）。

        response_text (TEXT): 模型返回的完整回答文本。

        response_time (TIMESTAMP): 回答获取的时间。

        （可选）usage_info (TEXT): 调用消耗的token数量、延迟等信息(JSON或字符串格式)。

    复合主键（query_id, model_name）可加索引，以方便查询某问题特定模型的缓存回答。

    Table: divergences（分歧分析表） – 存储对比两模型回答后的差异/分歧结果。

        id (INTEGER, PK): 分歧分析记录ID。

        query_id (INTEGER): 外键，关联对应的用户查询。

        diff_summary (TEXT): 分歧摘要描述，文本形式概括主要分歧点，供快速查看。

        diff_detail (TEXT): 详细的分歧结构数据，可能是JSON字符串或序列化后的结构（包括每个差异点的具体内容、类型等）。

        created_at (TIMESTAMP): 分歧分析生成时间。

    Table: structures（解耦结构表） – 存储结构化解耦模块输出的数据结构。

        id (INTEGER, PK): 记录ID。

        query_id (INTEGER): 外键，对应用户查询。

        structured_data (TEXT): 结构化的表示数据，JSON或其他格式文本。例如包含对齐的要点列表、两模型各自观点等。由于SQLite对JSON有一定支持，也可以用JSON字段类型存储以便查询。

        created_at (TIMESTAMP): 生成时间。

    （考虑到分歧分析结果和结构化解耦结果可能都以JSON存储，也可将二者合并为一张表，或直接在divergences表里增加字段存JSON结构。但为了清晰，这里分开，表示两步处理。）

    Table: fused_answers（融合答案表） – 存储最终生成的综合答案。

        id (INTEGER, PK): 融合答案记录ID。

        query_id (INTEGER): 外键，对应用户查询。

        answer_text (TEXT): 融合后的最终答案文本。

        created_at (TIMESTAMP): 答案生成时间。

        （可选）notes (TEXT): 备注信息，例如是否引入了证据、评分等（可留空或用于调试）。

此外，为了记录证据检索阶段的结果，可在后续阶段增加：

    Table: evidence（证据资料表） – （阶段2新增）存储在证据检索/裁决中得到的参考资料或判断结果。

        如：id, query_id, diff_id（关联某个分歧点）, evidence_text（证据内容或引用）、source（证据来源URL或说明）、verdict（裁决结果，例如“模型A正确”）等字段。

各表通过 query_id 将相关的数据联结起来。查询表是核心，一条查询记录对应若干模型回答、一个分歧分析、一份结构化数据和一份最终答案。在SQLite中，可以使用外键约束维护引用完整性，也可以在应用逻辑中保证同步创建和删除相关记录。

字段说明：所有文本均使用UTF-8编码存储。对于长文本（如模型回答、融合答案），SQLite的TEXT类型可以存储相当大的内容，一般不会成为瓶颈。关键字段如模型名称、时间等会建立索引以提升查询性能。鉴于本系统主要面向单用户逐条查询处理，数据量不大，数据库结构以清晰易用为主，复杂的优化例如分区或视图暂不需要。
5. 各模块之间的执行链路和调用逻辑

下面描述系统各模块的工作流程以及它们之间的调用顺序。每次用户提出一个新问题，系统按照既定的链路依次执行，具体步骤如下：

    接收用户查询：用户通过命令行界面或函数调用向系统提供问题文本。主程序（main.py）创建一条查询记录插入数据库的queries表，并获取生成的query_id用于追踪。

    调用大模型API：主程序调用 模型调用模块，传入用户问题和需要调用的模型列表（GPT、Claude）。模型调用模块首先检查数据库中是否已有针对该确切问题的缓存回答。如果缓存命中（即之前调用过相同问题），则直接从model_responses表读取对应模型的回答内容【如果两模型都有缓存，可跳过API调用】；如果无缓存，则向外部API发送请求：

        并发地调用 OpenAI GPT 接口和 Anthropic Claude 接口，传入用户问题（必要时附加系统提示词指示风格）。

        等待两个模型返回生成的答案文本。收到结果后，将每个模型的回答插入model_responses表（一条问题会对应两条回答记录）。

    分歧检测：主程序调用 分歧检测模块，提供query_id或直接提供刚得到的两份回答文本。分歧检测模块对比response_text字段内容，识别差异与冲突（详见模块说明）。它产出分歧分析结果数据结构，并写入divergences表，包含该问题下模型回答的对比情况。

    结构化解耦：接着调用 结构化解耦模块，传入分歧分析结果和原始回答。该模块提取要点、重组内容形成结构化表示。完成后，将结构化数据（通常为JSON或文本格式）存入structures表与该查询关联。

    证据检索与裁决（可选）：（此步骤在阶段2引入） 如果开启证据支持，系统将在融合前增加这一步骤。针对divergences中标记的关键冲突点，调用 证据检索模块 查询外部资料。例如，对于存在冲突的事实陈述，自动生成查询去搜索权威来源（如专利数据库、维基百科、学术文章等）以获取支持其中某一说法的证据。检索到的证据和对冲突的裁决结果（如判定哪方正确）将记录在evidence表或临时变量中。这个过程可能调用网络API，需考虑耗时和失败情况（如未找到证据则标记为未决）。

    融合生成：最后主程序调用 融合生成模块，传入结构化解耦数据以及（如果有）证据检索结果。融合模块综合所有信息生成最终答案文本。具体来说，它会遍历结构化要点：

        对于无分歧的点，直接采用共同信息撰写；

        对于有差异的点，参考证据裁决结果决定采用哪种说法，或在答案中解释两种观点。融合模块可能再次借助GPT生成自然语言表述，将各点内容串联成通顺段落。生成过程中确保引用证据支持（如果提供了证据，则在答案中隐含体现出处，如“根据资料...”)。

        将完成的答案存储到fused_answers表，并输出给用户。

    结果返回与存储：融合模块的输出通过主程序返回给用户（打印到控制台或通过API接口返回字符串)。同时答案已在数据库保存，用户可稍后查询重复问题时直接获得缓存的融合答案，而无需重新走完整流程。

    日志与后处理：系统可以记录本次流程的日志，包括耗时、模型调用计数等，供开发者分析优化。如果需要，日志记录在文件或数据库中特定日志表中。

以上流程确保每次处理都有据可查、重要数据均有持久化存储，方便调试和改进。下面的时序图直观展示了系统各模块的调用顺序和交互（其中包含缓存判定和可选的证据步骤）：

sequenceDiagram
    participant U as 用户
    participant M as 模型调用模块
    participant G as GPT API
    participant C as Claude API
    participant D as 分歧检测模块
    participant J as 解耦模块
    participant F as 融合模块
    participant B as 数据库
    U->>M: 提出查询
    M-->>B: 查询缓存 (根据问题)
    alt 无缓存
        M->>G: 调用GPT模型API
        M->>C: 调用Claude模型API
        G-->>M: 返回回答1
        C-->>M: 返回回答2
        M-->>B: 存储两模型回答
    else 有缓存
        M-->>B: 读取缓存回答
    end
    M-->>D: 提供模型回答文本
    D->>D: 对比分析回答分歧
    D-->>B: 存储分歧分析结果
    D-->>J: 传递分歧结构数据
    J->>J: 重组解耦回答结构
    J-->>B: 保存结构化数据
    J-->>F: 提供解耦后的结构
    opt 证据检索阶段
        F->>F: 调用证据模块验证冲突
    end
    F->>F: 融合生成最终答案
    F-->>B: 保存融合答案
    F-->>U: 返回融合答案

图：模块执行链路时序图。从用户提问到返回答案的完整流程，展示了缓存查询、并行API调用、差异分析、结构化处理、证据检索（可选）和答案融合的顺序。

整个执行过程中，模块之间采用函数或方法调用传递数据。在实现上，main.py 将串联调用各模块，例如：

# 伪代码示例
query_id = db.save_query(question)
answers = model_invoker.get_answers(question, query_id)
diff_result = divergence_detector.compare(answers, query_id)
structure = decoupler.restructure(diff_result, answers, query_id)
if enable_evidence:
    evidence = evidence_module.fetch_and_judge(diff_result)
else:
    evidence = None
final_answer = fusion_generator.generate(structure, evidence)
db.save_fused_answer(query_id, final_answer)
return final_answer

通过以上链路，系统将模型的不同回答转化为更可靠、更全面的结果输出。在后续开发阶段，这一链路可以扩展（例如增加循环询问机制、多模型投票等），但基本的调用逻辑如上，是整个系统运作的基础。
6. 开发阶段划分

为循序渐进地构建完整系统，我们将开发过程划分为多个阶段，每个阶段在前一阶段基础上增加功能，逐步演进系统能力。以下是推荐的开发阶段及其目标：

    阶段1：最简系统原型 – 实现基本的双模型调用、分歧检测和结果输出。首先搭建起模块化框架和数据库：

        功能范围：调用两个模型获取回答，比较文本差异，生成一个简单融合输出。此阶段注重端到端跑通流程。可以暂不实现证据检索和复杂的结构化逻辑，分歧检测也可采用基本的字符串对比。融合输出可以简单地将两模型的回答和差异列出来，或采取其中较完整的一方答案作为输出（注明整合了另一方的附加信息）。

        技术要点：设置好OpenAI和Anthropic API的调用（需要读取API Key），建立SQLite数据库和基本表（至少包含queries和model_responses用于缓存）。实现模块调用的基本接口，使主流程可以依序调用。确认各部分联调正常，能够接受控制台输入并打印出融合结果。

        验收：用几个示例问题测试，确保能成功从两个模型获取回答、检测出明显差异并输出结果。验证数据库确实存储了回答并可重复查询。此阶段产出一个可运行的原型系统，为后续功能扩展打下基础。

    阶段2：加入证据裁决 – 在基本系统上增强对分歧的处理深度，引入第三方证据以提高答案可靠性。

        功能范围：实现证据检索模块。当分歧检测发现模型A与模型B在某关键事实或结论上不一致时，系统应尝试检索权威信息进行佐证。例如，针对一项科技细节的争议，自动搜索相关技术文献/专利说明，或者查询维基百科词条。根据检索到的资料判断哪一模型的说法更准确，或获取足够信息融合两者。然后在融合答案时引用这些证据来支持最终结论。

        实现方式：可以使用公开的API（如搜索引擎Web API、数据库查询接口等）获取资料。由于用户在本地运行，可要求其提供一个搜索API密钥，或者使用现有的数据源。本模块需要将查询关键词提取自动化，例如从分歧点中抓取名词短语用于搜索。检索到的数据经过简要处理（截取相关片段）后，输出给融合模块。可能需要更新数据库结构（新增evidence表）来保存证据以及裁决结果（例如用布尔值或枚举表示“模型A正确/模型B正确/未确定”）。

        融合改进：融合模块利用证据裁决结果调整输出措辞。例如，“经查证，Claude提到的X更符合资料，因此采用X”。在答案中可选择明示或暗示依据了外部资料。此阶段重点是使系统有能力自动判别真伪，减少错误传播。

        验收：设计几个模型容易产生矛盾回答的测试问题，验证系统能检索到相关信息并据此修改最终答案。检查日志或数据库记录，确认证据检索被正确调用、结果被记录和应用。评估融合答案的可信度提升。

    阶段3：引入知识图谱结构 – 提升系统对复杂逻辑和领域知识的处理，使用知识图谱等结构化表示来增强分歧分析和答案融合。

        功能范围：实现知识图谱构建和结构化推理。即在结构化解耦模块中，引入对模型回答内容的知识抽取，将关键实体、概念及它们的关系构造成图谱。然后利用图谱对比模型回答之间的差异，以及发现各自可能遗漏的节点，指导更全面的融合。

        实现方式：可使用NLP技术从文本中提取 三元组 (主语-谓语-宾语) 或 概念节点。例如，将回答转换成若干 (实体/概念) - (关系) - (实体/概念) 的集合。把GPT的回答图谱和Claude的回答图谱合并比较：重合的部分表示两者共识，只有在一个图中的节点/边表示独有信息或观点冲突。通过图算法可以发现冲突（例如两图对同一实体的属性赋值不同）或缺失点（一方图谱有节点另一方没有）。在融合阶段，系统将尝试合并知识图谱，形成包含所有重要节点和一致关系的完整图谱，再将其转述为最终答案。

        模块改造：在这一阶段，结构化解耦模块需要显著增强，可能调用spaCy进行实体识别、用自定义规则提取关系，或者利用大型模型解析句子得到关系表。可以新建一个knowledge_graph子模块负责上述逻辑。数据库中，可将图谱信息以JSON或其他形式存储在structures表，或者单独建表存节点和边（如nodes, edges表）。融合模块也需调整逻辑，基于图谱进行合并而非逐段文本。

        额外收益：知识图谱方便与外部知识库对接。例如如果有行业专利数据库，系统可将图谱节点与外部知识图谱对齐，发现新的关联。这属于潜在扩展方向。

        验收：用一两个复杂问题测试两模型回答差异，例如涉及多步骤推理的问题。检查系统是否成功构建了反映两答案内容的图结构，并发现了关键差异。生成的最终答案应更有条理，覆盖更全面的信息点。通过日志或调试输出确认图谱在融合中的作用（例如看到系统将两个模型各自的几点全部囊括，矛盾之处选择了一个）。知识图谱的正确性和有用性由开发者人工评估。

各阶段开发完成后都应进行充分测试，确保新功能集成不破坏原有功能。由简入繁的阶段划分，保证用户（借助GPT-5.3-Codex代理）可以逐步实现复杂功能：先搭建框架，再增强智能。最终系统将在阶段3具备高度完善的双模型分歧分析与融合回答能力，可应用于专利撰写等需要严谨核验的场景。
7. GPT‑5.3‑Codex 可用于各阶段任务的提示词模板样例

在每个开发阶段，用户可以编写合适的**提示词（Prompt）**引导 GPT-5.3-Codex 来生成、调试代码，实现既定功能。下面分别给出各阶段的一些提示示例。这些提示词语言风格尽量明确具体，以确保Codex正确理解需求并执行。

阶段1 开发 – 初始系统搭建：用户可首先让 GPT-5.3-Codex 创建项目骨架和实现基础功能。例如：

    开发请求：请使用Python创建一个名为“双模型分歧检测与融合”的项目，按照模块化架构编写代码。需要包含：

        一个 main.py 脚本，负责读取用户输入的问题，调用各模块并最终打印融合答案。

        一个 modules 包，里面创建：

            model_invoker.py：定义 get_answers(question) 函数，调用OpenAI GPT和Anthropic Claude的API并返回两者的回答文本。请处理API调用异常，并将结果缓存到本地数据库。

            divergence_detector.py：定义 compare_answers(ans1, ans2) 函数，对比两段回答文本，找出差异之处并返回差异摘要（可以使用difflib生成对比结果）。

            fusion_generator.py：定义 generate_fused_answer(ans1, ans2, diff) 函数，根据两个模型的回答和差异摘要生成综合答案。可以简单地将两份回答合并，或先输出差异再给出综合结论。

            （可选）database.py：负责SQLite数据库的连接和基本读写操作，例如初始化表结构 queries 和 model_responses，以及提供 save_response、load_response 等方法。

        在项目根目录提供 requirements.txt，写入所需的库如 openai、anthropic、python-dotenv 等。
        实现要求：数据库使用SQLite，通过sqlite3模块建立，若不存在则自动创建。有新的用户问题时，将问题和时间插入queries表，再检查model_responses表是否已有缓存；如无则调用API获取。OpenAI和Anthropic API调用需读取环境变量中的API密钥。请确保代码结构清晰，函数命名自解释，并在重要步骤加上注释说明逻辑。

上述提示将指导 Codex 创建初始项目文件及代码。Codex 可能先输出 main.py 内容，再依次输出各模块代码。用户可以多次运行/调整提示，以获得完整的项目文件。

阶段1 测试与调试：在Codex生成初版代码后，用户可以要求其编写测试用例或直接运行检查。例如：

    测试请求：请为 main.py 编写一个简单的测试代码，模拟输入一个问题字符串，例如“火星和地球的距离是多少？”，调用主流程并输出结果。由于是真实调用大模型API，请在测试中对model_invoker部分进行模拟，假设GPT返回“火星到地球约2.25亿公里”，Claude返回“地球到火星平均距离约2亿公里”，模拟这两个回答，然后测试后续分歧检测和融合功能是否正确处理并输出合理结果。 

Codex据此可能生成一个测试函数或脚本，用户运行后检查输出是否符合预期。如果发现错误或异常（例如数据库未正确写入、diff结果格式不理想等），用户可继续使用提示引导Codex修复：

    调试请求：刚才运行时发现 divergence_detector.compare_answers 返回的差异文本不够清晰，请修改该函数，将差异结果整理为更易读的格式。例如，用“差异: …”的前缀和换行来列出模型A独有内容和模型B独有内容分别的简短描述。 

Codex会据此更新 divergence_detector.py 中的实现，改进输出格式。通过这种 反馈-修改 循环，逐步完善阶段1功能，直到对基本流程满意。

阶段2 增强 – 引入证据检索：完成基础系统后，用户在提示词中加入新需求，指导Codex添加证据模块并整合。例如：

    新功能请求：现在，请升级系统，在融合答案前增加“证据检索与裁决”步骤。具体要求：

        创建一个新模块 evidence_retriever.py，实现函数 fetch_evidence(diff_points)，其中 diff_points 可以是分歧检测模块输出的差异点列表。这个函数对于每个关键差异点执行一个网络搜索（可使用 wikipedia 库根据差异中的关键词搜索相关百科内容），获取简短的参考资料文本。如果找到信息支持某一方观点，则记录裁决结果（例如返回一个字典，键为差异点，值为 'A' 或 'B' 或 'unknown' 表示支持A方或B方）。

        修改 fusion_generator.generate_fused_answer 函数，将上一步得到的 evidence 结果作为参数传入。融合答案时，如果有证据表明某模型的说法正确，则在最终答案中偏向该说法，并加入引用依据的表述（例如“（经查证）”或引用数据）。若无定论则保留中立语气说明两种可能。

        更新数据库，在 fused_answers 表中增加一列 evidence_used，记录本次融合是否用了外部证据，证据来源是什么（简要说明即可）。
        注意：保证新增模块整合后，原有功能仍正常。证据检索过程可能较慢，可在实现时考虑缓存已查询过的关键词结果（例如在内存字典中）。

Codex按照要求，会生成 evidence_retriever.py 新模块代码（使用requests或wikipedia库搜索），修改 fusion_generator.py 相应函数，加上处理证据的逻辑，以及在数据库管理中添加字段。由于这一步涉及外部API，Codex可能就搜索部分做简单实现。用户拿到代码后，可以自己补充真实API密钥或调整搜索方案。

测试阶段2：用户可以提示Codex编写新的测试或直接运行实际示例检查证据功能。例如：

    证据功能测试：请编写代码模拟以下情况：GPT回答“太阳系中最大的行星是木星”，Claude回答“太阳系中最大的行星是木星，但是土星的体积也很大”。分歧检索模块应该识别不存在冲突（都是木星），因此不需要证据裁决，最终融合应简洁回答“太阳系最大的行星是木星”。然后，模拟另一情况：GPT回答“X技术专利申请于2020年”，Claude回答“X技术专利申请于2018年”。证据检索模块应检索X技术相关专利信息，并裁决出正确年份。例如假设结果支持Claude说法是对的，那么融合输出应采用2018年的信息并注明“经查证”。 

通过这样的复合提示，Codex可以生成测试代码或说明如何验证逻辑。用户运行测试并观察，如果融合结果和证据引用符合预期，则阶段2功能完成。如不符合，可以进一步提示Codex修改相应模块细节（例如证据检索没有正确解析年份，需要改进解析逻辑等）。

阶段3 增强 – 引入知识图谱：最后，用户提示Codex实现知识图谱相关功能。由于这部分较复杂，可分步提示：

    知识图谱功能请求：我们计划进一步改进分歧分析，借助知识图谱。请完成以下任务：

        在 modules 新增文件 knowledge_graph.py，实现 build_graph_from_text(text) 函数。它应使用 spaCy 或正则，从给定文本中提取主干信息（比如“主体-动词-宾语”三元组）。可以考虑句法依存分析找出主语、谓语、宾语，以及重要的定语从句。如一句话“火星是太阳系的第四颗行星，拥有两个卫星”，可提取出关系：("火星","是","第四颗行星"), ("火星","拥有","两个卫星")。将提取结果组织为图的数据结构（可以用NetworkX的有向图，节点是名词，边是关系）。

        实现 compare_graphs(graphA, graphB) 函数，对比两个图谱的差异。比如找出现仅在A图中存在的节点或关系，仅在B图中的，以及两者共同的节点。特别关注是否有矛盾关系（如A里有“X是Y”，B里有“X不是Y”这种冲突）。返回图谱差异摘要数据结构。

        修改 divergence_detector，使其不仅返回文本diff，还调用上述 build_graph_from_text 分别为GPT和Claude的回答构建知识图，然后调用 compare_graphs 找出知识层面的差异。将这些差异整合进分歧分析结果的数据结构中（例如增加字段 graph_diff 保存图谱差异）。

        修改 fusion_generator 使其利用图谱信息改善答案融合。例如，对于模型A提到但模型B遗漏的节点，在最终答案中加入相关说明以更全面；对于冲突的关系，尝试借助证据或上下文决定采用哪个。
        注意：这一改动较大，请确保各模块接口兼容。graph构建初期可以简化处理，如只打印提取的三元组验证效果。逐步完善提取准确性。

Codex可能先生成 knowledge_graph.py 代码，实现文本解析为图（可能使用简单规则或假设库已安装）。再更新 divergence_detector 和 fusion_generator 相应部分。由于知识图谱是复杂任务，Codex的输出可能需要多轮调整。用户可以提示更具体的修改，例如如果Codex对 spaCy 用法不正确，可以提醒它修正。

阶段3 测试：知识图谱功能难以自动测试，但用户可以选取一段长回答，让Codex展示图谱提取效果：

    图谱测试请求：给定文本“A型设备包括B组件和C组件。B组件用于加热材料，C组件用于控制温度。”请调用 knowledge_graph.build_graph_from_text 输出提取的图谱节点和关系。 

Codex 会产出如：节点["A型设备","B组件","C组件","材料","温度"]，关系[("A型设备","包括","B组件"),("A型设备","包括","C组件"),("B组件","用于","加热材料"),("C组件","用于","控制温度")]。用户根据合理性判断并让Codex优化提取规则。如果满意，再让系统处理两个模型回答的图谱比较，检查 compare_graphs 输出是否标识出了差异节点等。一切正常后，阶段3开发结束。

以上提示词示例展示了用户如何与GPT-5.3-Codex交互，逐步开发（实现新模块）、测试验证（编写并运行测试）、调优更新（根据测试结果修改代码）。通过精细的指令和及时的反馈，Codex代理可以独立构建并演化整个系统。
8. 附录：脚本目录结构、运行方式说明、环境配置建议

项目目录结构 – 开发完成后，项目应具有清晰的文件组织。建议的目录结构如下：

dual_model_divergence_project/
├── main.py                        # 主入口脚本，执行整套流程
├── modules/                       # 功能模块包
│   ├── __init__.py
│   ├── model_invoker.py           # 模型调用模块
│   ├── divergence_detector.py     # 分歧检测模块
│   ├── decoupler.py               # 结构化解耦模块
│   ├── fusion_generator.py        # 融合生成模块
│   ├── evidence_retriever.py      # （阶段2新增）证据检索模块
│   └── knowledge_graph.py         # （阶段3新增）知识图谱模块
├── data/
│   └── responses.db               # SQLite 数据库文件（自动生成）
├── tests/                         # 测试用例（可选）
│   ├── __init__.py
│   └── test_basic_flow.py         # 阶段1 基础功能的测试
├── requirements.txt               # Python依赖列表
├── .env                           # 环境变量配置文件 (API keys 等)
└── README.md                      # 使用说明文档

    main.py 会导入各模块并按照流程顺序调用，实现交互式或批处理的问答。它可以设计成运行后等待用户输入问题，然后输出答案并继续等待下一个问题（交互模式）；也可设计接受命令行参数直接回答一次后退出。

    modules 包内各文件对应本报告描述的模块功能，在实现时可能会有一些辅助函数按需要加入。例如 database.py 如果存在，可放在modules下或单独的db/目录。

    data/responses.db 是SQLite数据库文件，首次运行程序时由数据库管理模块自动创建。默认路径可在代码中指定，如当前目录下data/responses.db，也可通过环境变量自定义。

    tests 目录用于存放测试代码，方便对各模块进行单元测试或集成测试。开发过程中Codex可帮助编写这些测试。

    requirements.txt 列出所需安装的依赖库，例如：

    openai>=0.27.0
    anthropic>=0.3.0
    python-dotenv>=1.0.0
    wikipedia>=1.4.0       # 如果使用维基百科API
    spacy>=3.5.0           # 如果使用spaCy进行NLP
    networkx>=2.8          # 如果使用NetworkX处理图

    用户应根据实际用到的库调整版本并安装。

    .env 文件用于存放配置的环境变量，如：

    OPENAI_API_KEY="sk-xxxxxx"
    ANTHROPIC_API_KEY="api-key-xxxxxx"

    这个文件不应提交到版本控制。运行时，程序利用 python-dotenv 自动加载其中的变量，或者用户也可自行将其导入环境。

运行方式说明 – 完成开发和配置后，用户可以通过以下步骤运行系统：

    创建虚拟环境（可选）：为了避免与系统Python环境冲突，推荐创建虚拟环境：

    python3 -m venv venv 
    source venv/bin/activate   # Windows下使用 venv\Scripts\activate

    然后在激活的环境中安装依赖：

    pip install -r requirements.txt

    配置API密钥：在项目根目录下创建 .env 文件（或以其他方式设置系统环境变量）包含OpenAI和Anthropic的API密钥。如上所示填入各自的key值。确保在代码中使用了load_dotenv()加载该文件。

    初始化数据库：首次运行时，main.py 会调用数据库管理模块自动建立SQLite数据库文件及表。不需要用户手动创建表，但要求对项目目录具有写权限。如果要手动检查数据库，可以使用SQLite可视化工具打开 data/responses.db 查看表结构和内容。

    执行程序：运行 python main.py 启动主程序。如果是交互模式，程序会提示输入问题；若实现为单次运行模式，可在命令后加问题参数。例如：

    python main.py "请问太阳系中最大的行星是哪一颗？"

    程序将输出综合两个模型的答案。如果需要反复提问，交互模式更方便。退出交互可输入特定命令（例如exit或Ctrl+C终止）。

    查看日志和结果：如实现了日志，用户可在控制台或日志文件中看到各阶段处理信息（例如“已从缓存获取GPT回答”“证据检索结果：XXX”等）。这些有助于理解系统工作过程。最终答案会直接打印给用户。与此同时，所有数据已记录在数据库，可以事后查询。例如，可以打开数据库检查 fused_answers 表验证对应的问题输出是否存储成功。

环境配置建议：开发阶段应在联网环境下进行，以便GPT-5.3-Codex能够安装依赖和调用API进行调试。但部署时，除非需要证据检索联网，调用OpenAI/Anthropic API本身也需要互联网。用户应确保服务器具备稳定的网络连接和足够的API配额。对API密钥等敏感信息，利用环境变量和.env存储是安全实践。另外，如果在生产环境长期运行，考虑在代码中加入对API返回的内容进行安全过滤（如OpenAI提供的内容过滤机制）以及异常重试策略，从而提高系统稳定性。

最后，随着GPT-5.3-Codex 自动生成的代码不断演化，建议定期整理文档（更新README.md）以反映最新的用法和功能变更，确保即使用户不具备编程能力也能根据文档顺利安装、运行和使用该系统，实现预期的“双大模型逻辑分歧检测与结构化解耦”目标。
Citations

GitHub - openai/openai-python: The official Python library for the OpenAI API
https://github.com/openai/openai-python

GitHub - openai/openai-python: The official Python library for the OpenAI API
https://github.com/openai/openai-python

Developer quickstart | OpenAI API
https://platform.openai.com/docs/quickstart

Developer quickstart | OpenAI API
https://platform.openai.com/docs/quickstart

GitHub - anthropics/anthropic-sdk-python
https://github.com/anthropics/anthropic-sdk-python

GitHub - anthropics/anthropic-sdk-python
https://github.com/anthropics/anthropic-sdk-python

sqlite3 — DB-API 2.0 interface for SQLite databases — Python 3.14.3 documentation
https://docs.python.org/3/library/sqlite3.html

# 任务总览（必须严格执行）
你是 **GPT‑5.3‑Codex**，运行在 **Agent 模式**，可以：
- 进行联网检索与阅读（专利/论文/指南/政策解读）
- 创建/编辑本地文件（Markdown/Word/PDF/图片/表格）
- 运行脚本（优先 Python）来自动排版、生成 docx、生成附图
- 使用多线程/多工作树/多 Agent 并行（如果你的环境支持）

## 0. 你的唯一目标
在**尽量降低与现有专利冲突风险**的前提下，**自动产出一套“可提交的中国发明专利申请文件”**，主题为：

> **双大模型逻辑分歧的自动检测与结构化解耦算法**  
（可扩展：多模型、多 Agent；但核心必须保持“双模型分歧检测 + 分歧点结构化解耦 + 子问题裁决/证据聚合 + 融合输出”的技术方案）

最终输出必须包含：
1) 《说明书》（含技术领域、背景技术、发明内容、附图说明、具体实施方式）  
2) 《权利要求书》（至少 1 组方法独立权利要求 + 若干从属；并至少给出“装置/设备/存储介质”权利要求）  
3) 《说明书摘要》（≤300字，含技术领域、技术问题、技术方案要点、主要用途；不得宣传性用语）  
4) 《摘要附图》与《说明书附图》：给出可用的流程图/模块图（至少 4~6 张），并保证附图标记引用一致  
5) 《现有技术检索与差异化对比报告》（你的内部交付物，但必须输出给用户，帮助规避撞专利）
6) 《可提交格式包》：生成 **docx**（优先）和可选 PDF；并附带“用户仅需替换的占位符清单”。

> 重要：你不能保证一定授权，但必须把“可授权性风险”显式做成检查清单，并尽量用结构性差异降低风险。

---

# 1. 工作原则（强约束）
## 1.1 交互策略（减少用户负担）
- 用户零代码。除非必须，否则不要让用户手工操作。
- 信息缺失时：使用 **占位符**（如【申请人名称】、【发明人】、【实施例参数】），继续推进，不要卡住。
- 仅在 3 个节点向用户提问（最多每次 3 个问题）：
  1) 申请人/发明人/联系人基本信息（可留空用占位符）
  2) 是否要把“证据检索/外部知识库”作为实施例必选（默认：是）
  3) 是否优先申请“方法+装置+设备+介质”四件套（默认：是）

## 1.2 原创性与避撞要求（硬约束）
- 不得复制粘贴任何现有专利/论文的原文段落；必须改写为原创表述。
- 必须做“现有技术雷达”：
  - 至少检索 CN + US + WO（Google Patents / 国家公开渠道 / Espacenet / WIPO 均可）
  - 输出 Top 20 相关专利列表（标题、公开/授权号、申请人、核心权利要求点、与你方案的相似点）
  - 选出 Top 5 最相近专利做“要素对比表（claim chart）”
- 在拟定权利要求之前，先提出**至少 8 个“差异化技术特征候选”**，并将其组合成 2~3 套不同的权利要求路线（A/B/C 路线）。

## 1.3 中国发明专利写作必须合规
- 权利要求：清楚、简要；以技术特征限定；避免纯“规则/方法/商业逻辑”措辞。
- 说明书：充分公开，使本领域技术人员能够实现；实施例要具体。
- AI/算法相关：必须体现为“技术方案”，强调**技术问题—技术手段—技术效果**闭环；必要时补充“数据结构、计算流程、资源消耗优化、鲁棒性提升”等可验证技术效果。
- 伦理与合规：避免任何违法、歧视性决策机制；在说明书加入“数据合规/脱敏/权限控制/审计”实施方式（可作为从属权利要求点）。

---

# 2. 项目工程化交付（让用户可一键打包提交）
你必须在工作目录创建如下结构（如果目录已存在则增量更新）：

/patent_cn/
  /00_admin/                 # 占位符与用户信息
    applicant_inventor.json
    placeholder_map.md
  /01_prior_art/              # 现有技术检索与对比
    search_queries.md
    patent_list_top20.md
    closest5_claim_chart.xlsx
    novelty_strategy.md
  /02_invention_design/       # 技术方案定稿
    problem_solution_effect.md
    system_architecture.md
    data_structures.md
    algorithm_steps.md
    embodiments_outline.md
  /03_claims/                 # 权利要求书
    claims_route_A.md
    claims_route_B.md
    claims_route_C.md
    claims_final.docx
  /04_spec/                   # 说明书 + 摘要
    spec_draft.md
    spec_final.docx
    abstract.md
    abstract_final.docx
  /05_drawings/               # 附图
    fig1_system_architecture.png
    fig2_method_flow.png
    fig3_disagreement_graph.png
    fig4_decoupling_subquestions.png
    fig5_iteration_feedback_loop.png
    fig6_data_structure.png
    drawings_list.md
  /06_packaging/              # 最终打包
    submission_checklist.md
    cnipa_format_check.md
    final_package_manifest.md
    export_pdf.log
  /scripts/
    build_docx.py
    build_figures.py
    lint_patent_text.py
    check_abstract_len.py
    claim_support_mapper.py

> 你必须让所有关键文件最后都变成 docx（至少：权利要求书、说明书、摘要）。用户只需要打开 docx 改占位符即可。

---

# 3. 里程碑与“频繁更新”机制（符合 Codex Agent 习惯）
你必须每完成一个里程碑，就输出：
- ✅ 已完成清单
- 🧩 下一步计划（不超过 5 条）
- ⚠️ 风险提示（如：最接近专利是谁、差异化是否足够、哪些点可能被认定为非技术性）
- 📁 生成/更新了哪些文件（路径）

里程碑：
M0 初始化目录 + 占位符系统  
M1 现有技术检索 Top20 + Top5 claim chart  
M2 差异化特征池 + 三路线权利要求草案  
M3 说明书草案（能支撑权利要求）  
M4 附图生成 + 附图说明一致性检查  
M5 docx 自动排版 + 摘要 300 字校验 + 最终包

---

# 4. 技术方案：必须把“方向二”写成可授权的技术方案
## 4.1 核心定义（你在说明书中必须给出）
- “模型A/模型B”：两个不同参数/架构/来源的大语言模型或多模态模型（可以同机或分布式）。
- “推理痕迹/思路片段”：可解析的中间过程表示（不要求泄露隐私推理链，可用“步骤化解释”“论点列表”“依据段落”替代）。
- “论点单元（Proposition Unit）”：把输出拆成最小可比较语义单元（结论/条件/步骤/约束/假设）。
- “分歧点（Divergence Point）”：在同一主题或同一论点单元下出现的矛盾、缺失、互斥假设、边界条件不一致等。
- “结构化解耦（Structured Decoupling）”：把每个分歧点变成一个或多个独立子问题，并分别裁决/保留多解，再回填到最终融合答案。

## 4.2 方法流程（至少 1 个主流程 + 2 个可选分支）
主流程必须包含以下阶段（写成步骤 S1…Sn，并在装置权利要求中对应模块）：
S1 同题双模型生成：对同一输入问题Q，向模型A、B发送标准化提示，得到输出 OA、OB（可含结构化解释）。  
S2 结构化切分：将 OA、OB 分解为论点单元集合 PA、PB，并附带主题标签/步骤编号/证据引用。  
S3 对齐与匹配：对 PA 与 PB 做语义对齐（embedding 相似度 + 规则 + 位置/编号约束），建立匹配对 M。  
S4 分歧识别：对每个匹配对做“蕴含/矛盾/无关/缺失”判定，形成分歧点集合 D，并分类（矛盾/遗漏/假设冲突/边界条件冲突/数值差异/概念定义差异）。  
S5 分歧解耦：对每个 d∈D 自动生成子问题 q_d，并抽取 A/B 各自的依据片段 rA_d、rB_d。  
S6 证据裁决（可选但默认开启）：调用检索/知识库/工具，形成证据 E_d；用“聚焦裁判器”仅在子问题层面判断支持哪方或保留多解，并生成结构化裁决记录 J_d。  
S7 融合合成：把一致部分直接合并；把分歧部分用 J_d 的结论或多情景方式写入最终输出 F；生成可解释的分歧映射表。  
S8 迭代收敛（可选）：将关键证据 E_d 反馈给模型A/B，再生成 OA’/OB’，重复 S2~S7，直到满足停止条件（分歧数下降到阈值/迭代次数上限/时间上限）。

## 4.3 你必须增加“差异化技术特征库”（用于规避现有专利）
你需要提出至少 8 个可写进从属权利要求的差异化点（示例方向）：
1) **分歧图谱**：将论点单元作为节点，蕴含/矛盾/依赖作为边，输出“分歧子图”。  
2) **最小冲突集提取**：对分歧图做最小割/最小不可满足子集(MUS)思想，定位“导致冲突的最小论点集合”。  
3) **分歧类型多级分类器**：NLI + 规则 + 数值校验联合判定，并输出置信度。  
4) **解耦子问题生成约束**：对子问题 q_d 施加“可验证性/可检索性/可执行性”约束，优先生成能通过工具验证的问题。  
5) **证据优先级队列**：对每个分歧点生成“证据检索计划”，并按预估信息增益排序执行。  
6) **可解释合成模板**：融合输出 F 采用固定结构（共识区、分歧区、裁决区、待验证区），并附 provenance（引用到 OA/OB 段落编号）。  
7) **资源受限调度**：在单机 CPU+GPU 场景下动态分配推理预算（例如：分歧越大，给裁判/检索越多预算）。  
8) **安全与合规模块**：对输入/输出进行隐私/歧视/违法风险检测，必要时改写或屏蔽。

你必须把这些差异化点映射到：
- 权利要求从属条款（至少 10 条从属）
- 说明书实施例（至少 2 个实施例覆盖“有证据检索”和“无证据仅保留多解”两种）

---

# 5. 专利检索与“避撞”工作流（必须做）
## 5.1 检索渠道与关键词
你必须同时使用中英文关键词并组合检索：
- 中文：大语言模型/双模型/多模型/分歧检测/矛盾检测/一致性校验/结构化解耦/子问题分解/自动裁判/证据聚合/融合回答/可解释性  
- 英文：LLM disagreement detection / contradiction detection / multi-model ensemble / structured decomposition / debate / LLM-as-a-judge / argument graph / entailment contradiction / claim alignment

## 5.2 输出内容（必须）
- Top20 专利清单（表格：标题、号、申请人、公开日、核心点、与你相似点）
- Top5 近似专利深读：用“要素对比表（claim chart）”逐条对比
- 结论：给出“可行差异化路线 A/B/C”，每条路线写：
  - 计划写入独权的 3~5 个核心特征
  - 计划写入从权的差异化特征
  - 风险：哪些点可能落入对方范围，如何改写/加限定

> 注意：你必须以“规避权利要求覆盖”为目标，而不是只看摘要相似。

---

# 6. 权利要求书生成策略（必须给多路线）
你必须先输出三套路线草案（A/B/C），再合并成最终版：
- 路线A：强调“分歧图谱 + 最小冲突集 + 结构化裁决记录”
- 路线B：强调“子问题可验证性约束 + 证据检索计划 + provenance 回填”
- 路线C：强调“单机双模型资源调度 + 迭代收敛停止条件 + 安全合规过滤”

最终交付：
- 至少 1 项**方法独立权利要求**（权1）
- 至少 1 项**装置独立权利要求**（权X）
- 至少 1 项**电子设备独立权利要求**（权Y）
- 至少 1 项**计算机可读存储介质独立权利要求**（权Z）
- 从属权利要求：建议 12~20 条（越多越“水”，但要有支撑、不要互相矛盾）

> 写作要点：
- 不要写成“让模型思考/判断/理解”；要写成“获取、解析、对齐、判定、生成、输出”等可实现的处理步骤。
- 关键名词必须在说明书有定义与实施方式支撑。
- 每条从属都要给出具体限定（阈值、数据结构、分类方式、迭代条件、输出格式等）。

---

# 7. 说明书写作策略（必须“充分公开”）
说明书必须包含：
- 技术领域：自然语言处理/多模型协同/智能问答一致性保障/可解释生成
- 背景技术：指出现有“投票/打分/裁判”不足（不定位具体论文原文），强调缺少“分歧点定位 + 结构化解耦 + 可解释融合”
- 发明内容：
  - 要解决的技术问题（至少 2 条：一致性、可解释性/可验证性、减少人工对比成本、降低幻觉/矛盾）
  - 技术方案（对应权利要求步骤/模块）
  - 有益效果（至少 5 条，最好可量化：分歧数量下降、人工核对时间下降、错误率下降等）
- 附图说明：逐图一句话说明
- 具体实施方式：
  - 实施例1：无外部证据，仅结构化拆解 + 多解保留
  - 实施例2：带外部检索/工具证据的裁决与回填
  - 实施例3（可选加分）：单机 CPU+GPU 双模型调度与迭代收敛
  - 给出关键参数示例：相似度阈值、NLI 置信度阈值、最大迭代次数、停止条件
  - 给出数据结构示例（JSON schema 或表格字段），确保能被本领域实现

---

# 8. 附图生成（必须可用）
你必须生成至少 4~6 张附图（黑白线条风格即可）：
- 图1：系统总体架构（模型A、模型B、解析模块、对齐模块、分歧检测、解耦与裁决、融合输出、存储与审计）
- 图2：方法流程图（S1~S8）
- 图3：分歧图谱示意（节点=论点单元，边=蕴含/矛盾/依赖）
- 图4：结构化解耦与子问题树
- 图5：迭代收敛反馈环
- 图6：输出结构化结果的数据结构（字段示意）

要求：
- 附图标记在说明书中引用一致（例如：101获取模块、102解析模块……）
- 摘要附图从上述附图中选择最能体现技术特征的一张（通常选 图2 或 图1）

实现方式：
- 优先：Python + matplotlib 画框图/流程图并导出 PNG（300dpi）
- 备选：Mermaid 生成后转图（若环境允许）

---

# 9. 自动化排版与格式化（你必须用脚本完成）
你必须编写并运行 Python 脚本实现：
- 将 /03_claims/*.md 与 /04_spec/*.md 转为 docx
- 设置页面：A4；页边距、行距、字号按中国专利常见格式（你要写成可配置项）
- 自动生成目录样式（可选）
- 自动检查：
  - 摘要字数（含标点）≤300
  - 权利要求编号连续
  - 附图标记引用存在性（说明书里出现的标记必须在附图清单中）
  - 术语一致性（模型A/B、分歧点、论点单元等）

并在 /06_packaging/ 输出：
- submission_checklist.md（用户提交前逐项勾选）
- placeholder_map.md（列出所有【】占位符及替换位置）
- final_package_manifest.md（列出最终文件名与用途）

---

# 10. 最终输出（你要在对话里给用户什么）
当你完成 M5 后，你必须在对话里输出：
1) 最终文件列表（含路径）
2) 关键“差异化要素”摘要（5~10 条）
3) Top5 近似专利与规避点（每个给一句话策略）
4) 用户只需做的 5 件事（极简步骤）
5) 如果用户要进一步“水”：提供“可追加从属权利要求素材池”（不破坏独权支撑）

---

# 11. 立即开始（现在执行）
按里程碑 M0→M5 执行。先做 M0：
- 创建目录与占位符系统
- 生成 search_queries.md（中英文组合）
- 然后开始 M1 的专利检索与整理
